= AI Assistant plugin
:navtitle: AI Assistant
:description: Sends queries to registered AI APIs and sets the results in the document or temporarily stores the results.
:description_short: Query AI APIs and accept results.
:keywords: plugin, ai, artificial intelligence, query, search.
:pluginname: AI Assistant
:plugincode: ai
:plugincategory: premium

include::partial$misc/admon-ai-pricing.adoc[]

include::partial$misc/admon-requires-6.6v.adoc[]

The {pluginname} plugin allows a user to interact with registered AI APIs by sending queries and viewing responses within a {productname} editor dialog.

Once a response is generated and displayed within the dialog, the user can choose to either:

. insert it into the editor content, at the current selection;
. type another query to further refine the response generated by the AI; or
. discard or close the dialog.

Users can retrieve a history of their conversations with the AI using the xref:#getThreadLog[`getThreadLog` API].

[IMPORTANT]
.On the absence of an {pluginname} demo
====
This initial release of the {pluginname} developer documentation does not include an in-page working demo.

The logistics of setting up such a demo are still being investigated.

When a solution that is both useful and workable is found, it will replace this notice.
====

== Basic setup

To add the {pluginname} plugin to the editor, add both `{plugincode}` to the `plugins` option in the editor configuration and the `ai_request` function to the editor configuration.

For example:

[source,js]
----
tinymce.init({
  selector: 'textarea',  // change this value according to your HTML
  plugins: 'ai',
  toolbar: 'aidialog aishortcuts',
  ai_request: (request, respondWith) => { }
});
----

[IMPORTANT]
.Token use, default string added to prompts, and HTML formatting
====
The {pluginname} automatically prepends a default string to all prompts:

[source,text]
----
Answer the question based on the context below.
The response should be in HTML format.
The response should preserve any HTML formatting, links, and styles in the context.
----

This added string improves the UX and increases the response accuracy.

However, this added string increases token use.

As well, responses sent in HTML format also increase token use.
====

== Using a proxy server with {pluginname}

A proxy server can provide flexibility by allowing extra processing before the request is sent to an LLM AI endpoint and before returning the response to the user.

See the xref:ai-proxy.adoc[AI Proxy Server reference guide] for information on how to setup a proxy server for use with the {pluginname}.

NOTE: The xref:ai-proxy.adoc[AI Proxy Server reference guide] is, as its name notes, a reference. There is no single proxy server setup that is right or correct for all circumstances and other setups may be better for your use-case.


== Options

The following configuration options affect the behavior of the {pluginname} plugin.

include::partial$configuration/ai_request.adoc[][leveloffset=+1]

[ai_shortcuts]
include::partial$configuration/ai_shortcuts.adoc[][leveloffset=+1]

include::partial$misc/plugin-toolbar-button-id-boilerplate.adoc[]

include::partial$misc/plugin-menu-item-id-boilerplate.adoc[]

== Commands

The {pluginname} plugin provides the following {productname} commands.

include::partial$commands/{plugincode}-cmds.adoc[]

== Events

The {{pluginname}} plugin provides the following events.

include::partial$events/{plugincode}-events.adoc[]

== APIs

The {{pluginname}} plugin provides the following APIs.

include::partial$plugin-apis/{plugincode}-apis.adoc[]

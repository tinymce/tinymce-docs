[[ai_request]]
== `ai_request`

The {pluginname} uses the `+ai_request+` function to send prompts to an AI endpoint, and display the responses.

The `+ai_request+` function will be called each time a user submits a prompt. 

These prompts are only submitted with the {pluginname} dialog open, whether from typing in the dialog input field, or from using an {pluginname} shortcut.

The content returned within the `+ai_request+` function is displayed within the dialog, once a response is provided.

NOTE: This option is required to use the {pluginname} plugin.

*Type:* `+Function+`

=== Example: using `ai_request` and the `stream` callback to interface with the OpenAI Completions API

[source,js]
----
const fetchApi = import("https://unpkg.com/@microsoft/fetch-event-source@2.0.1/lib/esm/index.js").then(module => module.fetchEventSource);

const api_key = '<INSERT_API_KEY_HERE>'

tinymce.init({
  selector: 'textarea',  // change this value according to your html
  plugins: 'ai',
  toolbar: 'aidialog aishortcuts',
  ai_request: (request, respondWith) => {
    respondWith.stream((signal, streamMessage) => {
      const apiUrl = 'https://api.openai.com/v1/chat/completions';

      // Adds each previous query and response as individual messages
      const conversation = request.thread.flatMap((event) => {
        if (event.response) {
          return [
            { role: 'user', content: event.request.query },
            { role: 'assistant', content: event.response.data }
          ];
        } else {
          return [];
        }
      });
      
      // Forms the new query sent to the API
      const content = request.context.length === 0 || conversation.length > 0
        ? request.query
        : `Question: ${request.query} Context: """${request.context}"""`;

      const messages = [
        ...conversation,
        { role: 'system', content: request.system.join('\n') },
        { role: 'user', content }
      ];

      const requestBody = {
        model: 'gpt-3.5-turbo',
        temperature: 0.7,
        max_tokens: 800,
        messages,
        stream: true
      };

      const openAiOptions = {
        signal,
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${api_key}`
        },
        body: JSON.stringify(requestBody)
      };
      
      // This function passes each new message into the plugin via the `streamMessage` callback.
      const onMessage = (ev) => {
        const data = ev.data;
        if (data !== '[DONE]') {
          const parsedData = JSON.parse(data);
          const firstChoice = parsedData?.choices[0];
          const message = firstChoice?.delta?.content;
          if (message) {
            streamMessage(message);
          }
        }
      };
      
      const onError = (error) => {
        // Stop operation and do not retry by the fetch-event-source
        throw error;
      };

      // Use microsoft's fetch-event-source library to work around the 2000 character limit
      // of the browser `EventSource` API, which requires query strings
      return fetchApi
      .then(fetchEventSource => 
        fetchEventSource(apiUrl, {
          ...openAiOptions,
          openWhenHidden: true,
          onmessage,
          onerror
        })
      );
    });
  }
});
----

=== The `request` object

The `+ai_request+` function is given a request object as the first parameter, which has these fields:

`+prompt+`:: The submitted prompt as a string, combined with any current selection (when first opening the dialog) or the previous response. The {pluginname} plugin provides a customised format which combines these strings, though integrators are free to build their own with any of the other provided fields in the `+request+` object.

`+query+`:: The submitted prompt as a string, without any context.

`+context+`:: The current selection as a string, if any, or the current response displayed in the dialog. This can be combined with the `+query+`in a custom manner by the integrator to form a request. The current selection will be provided in HTML format, as will any displayed HTML response, and will increase token use.

`+system+`:: An array of messages which provide instructions for handling the user prompts. The `+system+` array:

[source, js]
----
[ 'Answer the question based on the context below.',
  'The response should be in HTML format.',
  'The response should preserve any HTML formatting, links, and styles in the context.' ]
----

`+thread+`:: The history of requests and responses within the dialog, provided as an array of objects.

[IMPORTANT]
.The default prompt and token use.
====
The {pluginname} automatically prepends the `+system+` value as a string to the `+prompt+` value. The prompt also combines the `+query+` and `+context+` values into a single string.

[source,text]
----
Answer the question based on the context below.
The response should be in HTML format.
The response should preserve any HTML formatting, links, and styles in the context.

Context: """<context>"""

Question: """<query>"""

Answer:
----

This string is intended to improve the UX and increases the response accuracy, and simplify the initial integration of the {pluginname} plugin.

However, this string uses more tokens than the `+query+` and `+context+` combined.
====


=== The `respondWith` object

The `+ai_request+` function provides an object containing two separate callbacks as the second parameter. These callbacks allow the integrator to choose how the response from the API will be displayed in the {pluginname} dialog.

Both of these callbacks expect a `+Promise+` which indicates that the response is either finished (when resolved), or interrupted (when rejected). The return type of the promise differs between callbacks.

Both callbacks provide a `signal` parameter.

`+signal+`:: If the user closes the dialog, or aborts a streaming response, the `+signal+` parameter can abort the request.

==== The `respondWith.string` callback

The `respondWith.string` callback provides functionality for displaying the entire response from the AI. 

The final response is to be returned as a string using a `+Promise+` within the `+resolve+` callback. This string will be displayed within the {pluginname} dialog.


==== The `respondWith.stream` callback

The `respondWith.stream` callback provides functionality for displaying streamed responses from the AI. 

This callback expects a `+Promise+` which resolves once the AI has finished streaming the response.

This callback provides `+streamMessage+` callback as the second parameter. Each new message is displayed in the dialog using the `+streamMessage+` callback.

`+streamMessage+`:: Takes a string and appends it to the content displayed in the {pluginname} dialog.

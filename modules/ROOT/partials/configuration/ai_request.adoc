[[ai_request]]
== `ai_request`

The {pluginname} uses the `+ai_request+` function to send prompts to an AI endpoint, and display the responses.

The `+ai_request+` function will be called each time a user submits a prompt. 

These prompts are only submitted with the {pluginname} dialog open, whether from typing in the dialog input field, or from using an {pluginname} shortcut.

The content returned within the `+ai_request+` function is displayed within the dialog, once a response is provided.

NOTE: This option is required to use the {pluginname} plugin.

*Type:* `+Function+`

=== Example: using `ai_request` to interface with the OpenAI Completions API

[source,js]
----
// This example stores the API key in the client side integration. This is not recommended for any purpose.
// Instead, an alternate method for retrieving the API key should be used.
const api_key = '<INSERT_API_KEY_HERE>';

const ai_request = (request, respondWith) => {
  const openAiOptions = {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${api_key}`
    },
    body: JSON.stringify({
      model: 'gpt-3.5-turbo',
      temperature: 0.7,
      max_tokens: 800,
      messages: [{ role: 'user', content: request.prompt }],
    })
  };
  respondWith.string((signal) => window.fetch('https://api.openai.com/v1/chat/completions', { signal, ...openAiOptions })
    .then(async (response) => {
      if (response) {
        const data = await response.json();
        if (data.error) {
          throw new Error(`${data.error.type}: ${data.error.message}`);
        } else if (response.ok) {
          // Extract the response content from the data returned by the API
          return data?.choices[0]?.message?.content?.trim();
        }
      } else {
        throw new Error('Failed to communicate with the ChatGPT API');
      }
    })
  );
};

tinymce.init({
  selector: 'textarea',  // Change this value according to your HTML
  plugins: 'ai',
  toolbar: 'aidialog aishortcuts',
  ai_request
});
----

[[request]]
=== The `request` object

The `+ai_request+` function is given a request object as the first parameter, which has these fields:

`+query+`:: The user-submitted prompt as a string, without any context. This is either the text as written by the user in the {pluginname} dialog, or the `+prompt+` as written in the shortcut object, when selected by the user from the shortcuts menu.

`+context+`:: The current selection as a string, if any, or the current response displayed in the dialog. This can be combined with the `+query+`in a custom manner by the integrator to form a request. The current selection will be provided in HTML format, as will any displayed HTML response, and will increase token use.

`+thread+`:: An array containing the history of requests and responses within the dialog, provided as an array of objects. This thread array is the same as is recorded in the xref:#getThreadLog[`+getThreadLog+` API], for current instance of the {pluginname} dialog.

`+system+`:: An array of messages which provide instructions for handling the user prompts. The `+system+` array:

[source, js]
----
[ 'Answer the question based on the context below.',
  'The response should be in HTML format.',
  'The response should preserve any HTML formatting, links, and styles in the context.' ]
----

`+prompt+`:: The submitted prompt as a string, combined with any current selection (when first opening the dialog) or the previous response. The {pluginname} plugin provides a customised format which combines these strings, though integrators are free to build their own with any of the other provided fields in the `+request+` object.

[IMPORTANT]
.The default prompt and token use.
====
The {pluginname} automatically prepends the `+system+` value as a string to the `+prompt+` value. The prompt also combines the `+query+` and `+context+` values into a single string.

[source,text]
----
Answer the question based on the context below.
The response should be in HTML format.
The response should preserve any HTML formatting, links, and styles in the context.

Context: """<the-selected-text>"""

Question: """<the-prompt>"""

Answer:
----

This string is intended to improve the UX and increases the response accuracy, and simplify the initial integration of the {pluginname} plugin.

However, this string uses more tokens than the `+query+` and `+context+` combined.
====


=== The `respondWith` object

The `+ai_request+` function provides an object containing two separate callbacks as the second parameter. These callbacks allow the integrator to choose how the response from the API will be displayed in the {pluginname} dialog.

Both of these callbacks expect a `+Promise+` which indicates that the response is either finished (when resolved), or interrupted (when rejected). The return type of the promise differs between callbacks.

Both callbacks provide a `signal` parameter.

`+signal+`:: If the user closes the dialog, or aborts a streaming response, the `+signal+` parameter can abort the request.

==== The `respondWith.string` callback

The `respondWith.string` callback provides functionality for displaying the entire response from the AI. 

The final response is to be returned as a string using `+Promise.resolve()+`. This string will be displayed within the {pluginname} dialog.


==== The `respondWith.stream` callback

The `respondWith.stream` callback provides functionality for displaying streamed responses from the AI. 

This callback expects a `+Promise+` which resolves once the AI has finished streaming the response.

This callback provides `+streamMessage+` callback as the second parameter, which should be called on each new partial message so the message can be displayed in the {pluginname} dialog immediately.

`+streamMessage+`:: Takes a string and appends it to the content displayed in the {pluginname} dialog.
